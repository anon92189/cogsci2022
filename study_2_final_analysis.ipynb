{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Experiment 2\n",
    "----------------------\n",
    "\n",
    "This notebook contains the python code used to analyze the data collected during Experiment 2 of the CogSci 2022 submission \"Evaluations of Causal Claims Reflect a Trade-Off Between Informativeness and Compression.\" It requires that R also be installed on your computer in order to run mixed ANOVAs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required packages.\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME']='/Library/Frameworks/R.framework/Resources' #The home for R on your computer may differ. \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects import pandas2ri, StrVector\n",
    "from rpy2.robjects.conversion import localconverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code imports and cleans the data in the file 'study_2_data.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and remove labels. \n",
    "data = pd.read_csv('study_2_data.csv')\n",
    "data=data.drop(labels=0,axis=0) \n",
    "data=data.drop(labels=1,axis=0)\n",
    "\n",
    "#Remove all data from participants who failed comprehension checks.\n",
    "inclusions = []\n",
    "for i in range(2,len(data)):\n",
    "    if data.D_CompCheck[i] == 'Drol' or data.B_CompCheck[i] == 'Bricofly' or data.C_CompCheck[i] == 'Chapagite':\n",
    "        inclusions = np.append(inclusions,[i])\n",
    "\n",
    "exclusions = [x for x in np.arange(2,len(data)) if x not in inclusions]\n",
    "\n",
    "data=data.drop(labels=exclusions,axis=0)\n",
    "\n",
    "#Remove all data from participants who rated any of the poor causal claims positively. \n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad55_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad98_1 != s]\n",
    "data = data.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code defines the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x):\n",
    "    marginal = [.01*.5+.55*.25+x*.25,1-(.01*.5+.55*.25+x*.25)] # defines a marginal distribution over the effect.\n",
    "    int_probs_noncomp = [.01,.01,.55,x] #defines the conditional probability distribution of the effect for each possible intervention on the non-compressed description of the cause.\n",
    "    int_dist_noncomp = [.25,.25,.25,.25] #defines the distribution over each possible intervention on the non-compressed description of the cause.\n",
    "    kullback_lieblers_noncomp = [sum([marginal[0]*np.log2(marginal[0]/int_probs_noncomp[i]),marginal[1]*np.log2(marginal[1]/(1-int_probs_noncomp[i]))]) for i in range(0,4)] #computes the Kullback-Liebler divergence between the marginal distribution over the effect and distribution given each possible intervention on the non-compressed description of the cause.  \n",
    "    int_probs_comp = [.01,(.55+x)/2] #computes the conditional probability distribution of the effect for each possible intervention on the compressed description of the cause.\n",
    "    int_dist_comp = [.5,.5] #defines the distribution over each possible intervention on the compressed description of the cause.\n",
    "    kullback_lieblers_comp = [sum([marginal[0]*np.log2(marginal[0]/int_probs_comp[i]),marginal[1]*np.log2(marginal[1]/(1-int_probs_comp[i]))]) for i in range(0,2)] #computes the Kullback-Liebler divergence between the marginal distribution over the effect and distribution given each possible intervention on the compressed description of the cause.\n",
    "    return sum([int_dist_noncomp[i]*kullback_lieblers_noncomp[i] for i in range(0,4)])-sum([int_dist_comp[i]*kullback_lieblers_comp[i] for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block constructs arrays whose values denote:\n",
    "\n",
    "1. The vignette shown to each participant (vignette)\n",
    "2. The information loss inherent in choosing a compressed over a non-compressed causal representation in the vignette shown to each participant (loss_vals)\n",
    "3. Whether the participant was shown a vignette in which compression involved coarsening a causal variable or eliding a background variable (condition).\n",
    "4. The participant's evaluation of the causal claim Compressed (comp_eval).\n",
    "5. The participant's evaluation of the causal claim High (high_eval).\n",
    "6. The participant's evaluation of the causal claim Low (low_eval).\n",
    "7. The difference between the participant's evaluation of the causal claim Compressed and the causal claim High (comp_high_diff).\n",
    "8. The difference between the participant's evaluation of the causal claim Compressed and the uniform avgerage of the participant's evaluation of the claims High and Low (comp_avg_diff).\n",
    "8. The difference between the evaluation of the causal claim High and the uniform avgerage of the participant's evaluation of the causal claim Low (high_low_diff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vignette = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        vignette = np.append(vignette,[-1])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        vignette = np.append(vignette,[0])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        vignette = np.append(vignette,[-1])\n",
    "        \n",
    "loss_vals = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        loss_vals = np.append(loss_vals,[loss(.7)])\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        loss_vals = np.append(loss_vals,[loss(.85)])\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        loss_vals = np.append(loss_vals,[loss(.98)])\n",
    "        \n",
    "condition = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Prop_Loss_2':\n",
    "        condition = np.append(condition,[-1])\n",
    "    if data.Group[i] == 'Stab_No_Loss' or data.Group[i] == 'Stab_Loss_1' or data.Group[i] == 'Stab_Loss_2':\n",
    "        condition = np.append(condition,[1])\n",
    "        \n",
    "comp_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood98_1[i])])\n",
    "\n",
    "            \n",
    "high_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1': \n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood98_1[i])])\n",
    "\n",
    "low_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1': \n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood55_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood98_1[i])])\n",
    "            \n",
    "\n",
    "\n",
    "comp_high_diff = comp_eval - high_eval\n",
    "comp_avg_diff = comp_eval - [.5*high_eval[i]+.5*low_eval[i] for i in range(0,len(data)-2)]\n",
    "high_low_diff = high_eval - low_eval                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Compressed and the causal claim High (the variable V-A in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Comp_High_Diff   R-squared:                       0.183\n",
      "Model:                            OLS   Adj. R-squared:                  0.171\n",
      "Method:                 Least Squares   F-statistic:                     15.21\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           5.59e-18\n",
      "Time:                        16:57:07   Log-Likelihood:                -819.00\n",
      "No. Observations:                 483   AIC:                             1654.\n",
      "Df Residuals:                     475   BIC:                             1687.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.2687      0.148      1.812      0.071      -0.023       0.560\n",
      "Vignette                    0.0100      0.180      0.056      0.956      -0.343       0.363\n",
      "Condition                   0.2284      0.148      1.541      0.124      -0.063       0.520\n",
      "Loss                       -2.9663      0.611     -4.858      0.000      -4.166      -1.766\n",
      "Vignette:Condition          0.0940      0.180      0.523      0.601      -0.259       0.447\n",
      "Vignette:Loss               0.5742      0.739      0.777      0.437      -0.877       2.025\n",
      "Condition:Loss             -1.3167      0.611     -2.156      0.032      -2.517      -0.117\n",
      "Vignette:Condition:Loss    -1.0179      0.739     -1.378      0.169      -2.469       0.433\n",
      "==============================================================================\n",
      "Omnibus:                       40.410   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              140.865\n",
      "Skew:                           0.287   Prob(JB):                     2.58e-31\n",
      "Kurtosis:                       5.583   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),comp_high_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Comp_High_Diff'])\n",
    "mod = smf.ols(formula='Comp_High_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Compressed and the average of their evaluations of causal claims High and Low (the variable V-B in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Comp_Avg_Diff   R-squared:                       0.058\n",
      "Model:                            OLS   Adj. R-squared:                  0.044\n",
      "Method:                 Least Squares   F-statistic:                     4.158\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           0.000186\n",
      "Time:                        16:57:07   Log-Likelihood:                -765.27\n",
      "No. Observations:                 483   AIC:                             1547.\n",
      "Df Residuals:                     475   BIC:                             1580.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.5247      0.133      3.955      0.000       0.264       0.785\n",
      "Vignette                    0.0387      0.161      0.241      0.810      -0.277       0.355\n",
      "Condition                   0.2180      0.133      1.643      0.101      -0.043       0.479\n",
      "Loss                       -1.6837      0.546     -3.082      0.002      -2.757      -0.610\n",
      "Vignette:Condition          0.1395      0.161      0.868      0.386      -0.176       0.455\n",
      "Vignette:Loss              -0.2913      0.661     -0.441      0.659      -1.590       1.007\n",
      "Condition:Loss             -0.9039      0.546     -1.654      0.099      -1.977       0.170\n",
      "Vignette:Condition:Loss    -0.7919      0.661     -1.198      0.231      -2.090       0.507\n",
      "==============================================================================\n",
      "Omnibus:                       53.145   Durbin-Watson:                   2.122\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              226.100\n",
      "Skew:                           0.370   Prob(JB):                     8.00e-50\n",
      "Kurtosis:                       6.269   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),comp_avg_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Comp_Avg_Diff'])\n",
    "mod = smf.ols(formula='Comp_Avg_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claims High and Low (the variable V-C in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          High_Low_Diff   R-squared:                       0.259\n",
      "Model:                            OLS   Adj. R-squared:                  0.248\n",
      "Method:                 Least Squares   F-statistic:                     23.69\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           1.22e-27\n",
      "Time:                        16:57:07   Log-Likelihood:                -766.11\n",
      "No. Observations:                 483   AIC:                             1548.\n",
      "Df Residuals:                     475   BIC:                             1582.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.5120      0.133      3.853      0.000       0.251       0.773\n",
      "Vignette                    0.0574      0.161      0.356      0.722      -0.259       0.374\n",
      "Condition                  -0.0210      0.133     -0.158      0.875      -0.282       0.240\n",
      "Loss                        2.5653      0.547      4.687      0.000       1.490       3.641\n",
      "Vignette:Condition          0.0910      0.161      0.565      0.572      -0.225       0.407\n",
      "Vignette:Loss              -1.7311      0.662     -2.615      0.009      -3.032      -0.430\n",
      "Condition:Loss              0.8256      0.547      1.508      0.132      -0.250       1.901\n",
      "Vignette:Condition:Loss     0.4521      0.662      0.683      0.495      -0.849       1.753\n",
      "==============================================================================\n",
      "Omnibus:                       44.318   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              125.204\n",
      "Skew:                           0.422   Prob(JB):                     6.49e-28\n",
      "Kurtosis:                       5.347   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),high_low_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'High_Low_Diff'])\n",
    "mod = smf.ols(formula='High_Low_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Compressed against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Comp_Eval   R-squared:                       0.019\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     1.328\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):              0.235\n",
      "Time:                        16:57:08   Log-Likelihood:                -804.05\n",
      "No. Observations:                 483   AIC:                             1624.\n",
      "Df Residuals:                     475   BIC:                             1658.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   1.8906      0.144     13.151      0.000       1.608       2.173\n",
      "Vignette                    0.2083      0.174      1.196      0.232      -0.134       0.551\n",
      "Condition                  -0.0895      0.144     -0.622      0.534      -0.372       0.193\n",
      "Loss                       -0.1572      0.592     -0.266      0.791      -1.321       1.006\n",
      "Vignette:Condition         -0.0421      0.174     -0.242      0.809      -0.384       0.300\n",
      "Vignette:Loss               0.1298      0.716      0.181      0.856      -1.277       1.537\n",
      "Condition:Loss             -0.7166      0.592     -1.210      0.227      -1.880       0.447\n",
      "Vignette:Condition:Loss    -0.6705      0.716     -0.936      0.350      -2.077       0.737\n",
      "==============================================================================\n",
      "Omnibus:                      131.840   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              283.299\n",
      "Skew:                          -1.451   Prob(JB):                     3.04e-62\n",
      "Kurtosis:                       5.378   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),comp_eval.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Comp_Eval'])\n",
    "mod = smf.ols(formula='Comp_Eval ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim High against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              High_Eval   R-squared:                       0.167\n",
      "Model:                            OLS   Adj. R-squared:                  0.154\n",
      "Method:                 Least Squares   F-statistic:                     13.56\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           5.17e-16\n",
      "Time:                        16:57:08   Log-Likelihood:                -816.38\n",
      "No. Observations:                 483   AIC:                             1649.\n",
      "Df Residuals:                     475   BIC:                             1682.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   1.6220      0.147     10.998      0.000       1.332       1.912\n",
      "Vignette                    0.1983      0.179      1.110      0.268      -0.153       0.549\n",
      "Condition                  -0.3179      0.147     -2.156      0.032      -0.608      -0.028\n",
      "Loss                        2.8091      0.607      4.625      0.000       1.616       4.002\n",
      "Vignette:Condition         -0.1361      0.179     -0.762      0.447      -0.487       0.215\n",
      "Vignette:Loss              -0.4444      0.735     -0.605      0.545      -1.888       0.999\n",
      "Condition:Loss              0.6001      0.607      0.988      0.324      -0.593       1.793\n",
      "Vignette:Condition:Loss     0.3474      0.735      0.473      0.636      -1.096       1.791\n",
      "==============================================================================\n",
      "Omnibus:                      134.924   Durbin-Watson:                   1.959\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              294.488\n",
      "Skew:                          -1.477   Prob(JB):                     1.13e-64\n",
      "Kurtosis:                       5.430   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),high_eval.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'High_Eval'])\n",
    "mod = smf.ols(formula='High_Eval ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Low against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Low_Eval   R-squared:                       0.044\n",
      "Model:                            OLS   Adj. R-squared:                  0.030\n",
      "Method:                 Least Squares   F-statistic:                     3.149\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):            0.00291\n",
      "Time:                        16:57:08   Log-Likelihood:                -832.62\n",
      "No. Observations:                 483   AIC:                             1681.\n",
      "Df Residuals:                     475   BIC:                             1715.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   1.1100      0.153      7.278      0.000       0.810       1.410\n",
      "Vignette                    0.1409      0.185      0.763      0.446      -0.222       0.504\n",
      "Condition                  -0.2969      0.153     -1.947      0.052      -0.597       0.003\n",
      "Loss                        0.2438      0.628      0.388      0.698      -0.990       1.478\n",
      "Vignette:Condition         -0.2271      0.185     -1.229      0.220      -0.590       0.136\n",
      "Vignette:Loss               1.2867      0.760      1.694      0.091      -0.206       2.779\n",
      "Condition:Loss             -0.2255      0.628     -0.359      0.720      -1.460       1.009\n",
      "Vignette:Condition:Loss    -0.1046      0.760     -0.138      0.891      -1.597       1.388\n",
      "==============================================================================\n",
      "Omnibus:                       44.435   Durbin-Watson:                   1.930\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.232\n",
      "Skew:                          -0.778   Prob(JB):                     1.67e-12\n",
      "Kurtosis:                       3.521   Cond. No.                         20.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),low_eval.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Low_Eval'])\n",
    "mod = smf.ols(formula='Low_Eval ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block generates Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(10,8)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.lineplot(x=loss_vals-.002, y=comp_eval, marker='o', err_style='bars',ci=95,label=\"Compressed\",linewidth=3)\n",
    "ax = sns.lineplot(x=loss_vals, y=high_eval, marker='o', err_style='bars',ci=95,linestyle='dashed',label=\"High\",linewidth=3)\n",
    "ax = sns.lineplot(x=loss_vals+.002, y=low_eval, marker='o', err_style='bars',ci=95,linestyle='dotted',label=\"Low\",linewidth=3)\n",
    "ax.set(ylim=(0,3))\n",
    "ax.set_ylabel('Mean Evaluation of Causal Claim',fontsize=30)\n",
    "ax.set_xlabel('Loss',fontsize=30)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('study2_barplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_High ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_High\n",
      "                        Effect     df  MSE         F   ges p.value\n",
      "1                     Vignette 1, 154 3.33      0.94  .005    .334\n",
      "2                    Condition 1, 154 3.33    2.79 +  .014    .097\n",
      "3           Vignette:Condition 1, 154 3.33      0.01 <.001    .906\n",
      "4                    Diff_Type 1, 154 0.89 29.06 ***  .038   <.001\n",
      "5           Vignette:Diff_Type 1, 154 0.89      0.00 <.001    .952\n",
      "6          Condition:Diff_Type 1, 154 0.89      0.74  .001    .391\n",
      "7 Vignette:Condition:Diff_Type 1, 154 0.89      0.64 <.001    .426\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_55=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        subject_55 = np.append(subject_55,[i,i])\n",
    "\n",
    "evals_high_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        evals_high_55 = np.append(evals_high_55,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "    \n",
    "vignette_for_anova_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        vignette_for_anova_55 = np.append(vignette_for_anova_55,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':                                                       \n",
    "        condition_for_anova_55 = np.append(condition_for_anova_55,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':                                                      \n",
    "        loss_vals_for_anova_55 = np.append(loss_vals_for_anova_55,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        diff_type_55 = np.append(diff_type_55,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_55.reshape(-1,1),vignette_for_anova_55.reshape(-1,1),condition_for_anova_55.reshape(-1,1),loss_vals_for_anova_55.reshape(-1,1),evals_high_55.reshape(-1,1),diff_type_55.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_High','Diff_Type'])\n",
    "\n",
    "\n",
    "packageNames = (\"afex\", \"emmeans\")\n",
    "utils = rpackages.importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "\n",
    "packnames_to_install = [x for x in packageNames if not rpackages.isinstalled(x)]\n",
    "\n",
    "if len(packnames_to_install) > 0:\n",
    "    utils.install_packages(StrVector(packnames_to_install))\n",
    "\n",
    "# convert pandas DF (\"tmp\") to R data.frame\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_High\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and Low when Loss=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE         F   ges p.value\n",
      "1                     Vignette 1, 154 3.34      0.08 <.001    .782\n",
      "2                    Condition 1, 154 3.34    3.60 +  .018    .060\n",
      "3           Vignette:Condition 1, 154 3.34      0.04 <.001    .848\n",
      "4                    Diff_Type 1, 154 1.05 33.28 ***  .049   <.001\n",
      "5           Vignette:Diff_Type 1, 154 1.05      1.66  .003    .200\n",
      "6          Condition:Diff_Type 1, 154 1.05      1.46  .002    .229\n",
      "7 Vignette:Condition:Diff_Type 1, 154 1.05      1.67  .003    .199\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_55 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        evals_low_55 = np.append(evals_low_55,[comp_eval[i],low_eval[i]])\n",
    "        \n",
    "        \n",
    "arr = np.hstack((subject_55.reshape(-1,1),vignette_for_anova_55.reshape(-1,1),condition_for_anova_55.reshape(-1,1),loss_vals_for_anova_55.reshape(-1,1),evals_low_55.reshape(-1,1),diff_type_55.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "        \n",
    "# convert pandas DF (\"tmp\") to R data.frame\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval\n",
      "                        Effect     df  MSE         F   ges p.value\n",
      "1                     Vignette 1, 157 1.90      0.78  .004    .380\n",
      "2                    Condition 1, 157 1.90      2.09  .009    .151\n",
      "3           Vignette:Condition 1, 157 1.90    3.97 *  .018    .048\n",
      "4                    Diff_Type 1, 157 0.75 16.49 ***  .029   <.001\n",
      "5           Vignette:Diff_Type 1, 157 0.75      0.09 <.001    .771\n",
      "6          Condition:Diff_Type 1, 157 0.75    3.82 +  .007    .052\n",
      "7 Vignette:Condition:Diff_Type 1, 157 0.75      0.00 <.001    .964\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_85=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        subject_85 = np.append(subject_85,[i,i])\n",
    "\n",
    "evals_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        evals_85 = np.append(evals_85,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "vignette_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        vignette_for_anova_85 = np.append(vignette_for_anova_85,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':                                                       \n",
    "        condition_for_anova_85 = np.append(condition_for_anova_85,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':                                                     \n",
    "        loss_vals_for_anova_85 = np.append(loss_vals_for_anova_85,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        diff_type_85 = np.append(diff_type_85,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_85.reshape(-1,1),vignette_for_anova_85.reshape(-1,1),condition_for_anova_85.reshape(-1,1),loss_vals_for_anova_85.reshape(-1,1),evals_85.reshape(-1,1),diff_type_85.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between High and Low when Loss=.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE          F   ges p.value\n",
      "1                     Vignette 1, 157 2.21     2.94 +  .014    .088\n",
      "2                    Condition 1, 157 2.21     3.09 +  .015    .081\n",
      "3           Vignette:Condition 1, 157 2.21     3.10 +  .015    .080\n",
      "4                    Diff_Type 1, 157 0.69 153.01 ***  .188   <.001\n",
      "5           Vignette:Diff_Type 1, 157 0.69     3.66 +  .006    .057\n",
      "6          Condition:Diff_Type 1, 157 0.69       1.67  .003    .199\n",
      "7 Vignette:Condition:Diff_Type 1, 157 0.69       0.01 <.001    .916\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        evals_low_85 = np.append(evals_low_85,[high_eval[i],low_eval[i]])\n",
    "        \n",
    "arr = np.hstack((subject_85.reshape(-1,1),vignette_for_anova_85.reshape(-1,1),condition_for_anova_85.reshape(-1,1),loss_vals_for_anova_85.reshape(-1,1),evals_low_85.reshape(-1,1),diff_type_85.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=.41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval\n",
      "                        Effect     df  MSE         F  ges p.value\n",
      "1                     Vignette 1, 160 1.68      0.85 .004    .358\n",
      "2                    Condition 1, 160 1.68    4.12 * .017    .044\n",
      "3           Vignette:Condition 1, 160 1.68      0.66 .003    .419\n",
      "4                    Diff_Type 1, 160 0.84 85.72 *** .151   <.001\n",
      "5           Vignette:Diff_Type 1, 160 0.84      1.29 .003    .257\n",
      "6          Condition:Diff_Type 1, 160 0.84      2.20 .005    .140\n",
      "7 Vignette:Condition:Diff_Type 1, 160 0.84      2.12 .004    .147\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_98=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        subject_98 = np.append(subject_98,[i,i])\n",
    "\n",
    "evals_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        evals_98 = np.append(evals_98,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "vignette_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        vignette_for_anova_98 = np.append(vignette_for_anova_98,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':                                                       \n",
    "        condition_for_anova_98 = np.append(condition_for_anova_98,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':                                                     \n",
    "        loss_vals_for_anova_98 = np.append(loss_vals_for_anova_98,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        diff_type_98 = np.append(diff_type_98,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_98.reshape(-1,1),vignette_for_anova_98.reshape(-1,1),condition_for_anova_98.reshape(-1,1),loss_vals_for_anova_98.reshape(-1,1),evals_98.reshape(-1,1),diff_type_98.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between High and Low when Loss=.41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE          F  ges p.value\n",
      "1                     Vignette 1, 160 1.47     5.02 * .019    .026\n",
      "2                    Condition 1, 160 1.47     5.77 * .022    .017\n",
      "3           Vignette:Condition 1, 160 1.47       0.63 .002    .428\n",
      "4                    Diff_Type 1, 160 0.85 273.89 *** .386   <.001\n",
      "5           Vignette:Diff_Type 1, 160 0.85    7.69 ** .017    .006\n",
      "6          Condition:Diff_Type 1, 160 0.85     3.15 + .007    .078\n",
      "7 Vignette:Condition:Diff_Type 1, 160 0.85       1.81 .004    .180\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 + 0.1   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        evals_low_98 = np.append(evals_low_98,[high_eval[i],low_eval[i]])\n",
    "        \n",
    "arr = np.hstack((subject_98.reshape(-1,1),vignette_for_anova_98.reshape(-1,1),condition_for_anova_98.reshape(-1,1),loss_vals_for_anova_98.reshape(-1,1),evals_low_98.reshape(-1,1),diff_type_98.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the perecentage of participants who strictly preferred Compressed to High across all three loss levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3924050632911392, 0.09937888198757763, 0.024390243902439025]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_loss_compressed_preferrers=0\n",
    "no_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss') and comp_eval[i]>high_eval[i]:\n",
    "        no_loss_compressed_preferrers=no_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        no_loss=no_loss+1\n",
    "\n",
    "moderate_loss_compressed_preferrers=0\n",
    "moderate_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1') and comp_eval[i]>high_eval[i]:\n",
    "        moderate_loss_compressed_preferrers=moderate_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        moderate_loss=moderate_loss+1\n",
    "        \n",
    "significant_loss_compressed_preferrers=0\n",
    "significant_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2') and comp_eval[i]>high_eval[i]:\n",
    "        significant_loss_compressed_preferrers=significant_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        significant_loss=significant_loss+1\n",
    "        \n",
    "[no_loss_compressed_preferrers/no_loss,moderate_loss_compressed_preferrers/moderate_loss,significant_loss_compressed_preferrers/significant_loss]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

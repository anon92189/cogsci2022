{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Code for Experiment 1\n",
    "----------------------\n",
    "\n",
    "This notebook contains the python code used to analyze the data collected during Experiment 1 of the CogSci 2022 submission \"Evaluations of Causal Claims Reflect a Trade-Off Between Informativeness and Compression.\" It requires that R also be installed on your computer in order to run mixed ANOVAs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required packages.\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME']='/Library/Frameworks/R.framework/Resources' #The home for on your computer may differ. \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects import pandas2ri, StrVector\n",
    "from rpy2.robjects.conversion import localconverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code imports and cleans the data in the file 'study_1_data.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and remove labels. \n",
    "data = pd.read_csv('study_1_data.csv')\n",
    "data=data.drop(labels=0,axis=0) \n",
    "data=data.drop(labels=1,axis=0)\n",
    "\n",
    "#Remove all data from participants who failed comprehension checks.\n",
    "inclusions = []\n",
    "for i in range(2,len(data)):\n",
    "    if data.D_CompCheck[i] == 'Drol' or data.B_CompCheck[i] == 'Bricofly' or data.C_CompCheck[i] == 'Chapagite':\n",
    "        inclusions = np.append(inclusions,[i])\n",
    "\n",
    "exclusions = [x for x in np.arange(2,len(data)) if x not in inclusions]\n",
    "\n",
    "data=data.drop(labels=exclusions,axis=0)\n",
    "\n",
    "#Remove all data from participants who rated any of the poor causal claims positively. \n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.B_StabLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.C_StabLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_PropLowBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad70_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad85_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabCompBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabHighBad98_1 != s]\n",
    "for i in range(0,4):\n",
    "    s = str(i)\n",
    "    data = data[data.D_StabLowBad98_1 != s]\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code defines the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x):\n",
    "    marginal = [.01*.5+.7*.25+x*.25,1-(.01*.5+.7*.25+x*.25)] # defines a marginal distribution over the effect.\n",
    "    int_probs_noncomp = [.01,.01,.7,x] #defines the conditional probability distribution of the effect for each possible intervention on the non-compressed description of the cause.\n",
    "    int_dist_noncomp = [.25,.25,.25,.25] #defines the distribution over each possible intervention on the non-compressed description of the cause.\n",
    "    kullback_lieblers_noncomp = [sum([marginal[0]*np.log2(marginal[0]/int_probs_noncomp[i]),marginal[1]*np.log2(marginal[1]/(1-int_probs_noncomp[i]))]) for i in range(0,4)] #computes the Kullback-Liebler divergence between the marginal distribution over the effect and distribution given each possible intervention on the non-compressed description of the cause.  \n",
    "    int_probs_comp = [.01,(.7+x)/2] #computes the conditional probability distribution of the effect for each possible intervention on the compressed description of the cause.\n",
    "    int_dist_comp = [.5,.5] #defines the distribution over each possible intervention on the compressed description of the cause.\n",
    "    kullback_lieblers_comp = [sum([marginal[0]*np.log2(marginal[0]/int_probs_comp[i]),marginal[1]*np.log2(marginal[1]/(1-int_probs_comp[i]))]) for i in range(0,2)] #computes the Kullback-Liebler divergence between the marginal distribution over the effect and distribution given each possible intervention on the compressed description of the cause.\n",
    "    return sum([int_dist_noncomp[i]*kullback_lieblers_noncomp[i] for i in range(0,4)])-sum([int_dist_comp[i]*kullback_lieblers_comp[i] for i in range(0,2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block constructs arrays whose values denote:\n",
    "\n",
    "1. The vignette shown to each participant (vignette)\n",
    "2. The information loss inherent in choosing a compressed over a non-compressed causal representation in the vignette shown to each participant (loss_vals)\n",
    "3. Whether the participant was shown a vignette in which compression involved coarsening a causal variable or eliding a background variable (condition).\n",
    "4. The participant's evaluation of the causal claim Compressed (comp_eval).\n",
    "5. The participant's evaluation of the causal claim High (high_eval).\n",
    "6. The participant's evaluation of the causal claim Low (low_eval).\n",
    "7. The difference between the participant's evaluation of the causal claim Compressed and the causal claim High (comp_high_diff).\n",
    "8. The difference between the participant's evaluation of the causal claim Compressed and the uniform avgerage of the participant's evaluation of the claims High and Low (comp_avg_diff).\n",
    "8. The difference between the evaluation of the causal claim High and the uniform avgerage of the participant's evaluation of the causal claim Low (high_low_diff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vignette = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        vignette = np.append(vignette,[-1])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        vignette = np.append(vignette,[0])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        vignette = np.append(vignette,[-1])\n",
    "        \n",
    "loss_vals = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        loss_vals = np.append(loss_vals,[loss(.7)])\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        loss_vals = np.append(loss_vals,[loss(.85)])\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        loss_vals = np.append(loss_vals,[loss(.98)])\n",
    "        \n",
    "condition = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Prop_Loss_2':\n",
    "        condition = np.append(condition,[-1])\n",
    "    if data.Group[i] == 'Stab_No_Loss' or data.Group[i] == 'Stab_Loss_1' or data.Group[i] == 'Stab_Loss_2':\n",
    "        condition = np.append(condition,[1])\n",
    "        \n",
    "comp_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.B_StabCompGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.C_StabCompGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_PropCompGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            comp_eval = np.append(comp_eval,[int(data.D_StabCompGood98_1[i])])\n",
    "\n",
    "            \n",
    "high_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1': \n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.B_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.B_StabHighGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.C_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.C_StabHighGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.D_PropHighGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            high_eval = np.append(high_eval,[int(data.D_StabHighGood98_1[i])])\n",
    "\n",
    "low_eval = []\n",
    "for i in range(0,len(data)):\n",
    "    if data.Vignette[i] == 'Bricofly':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1': \n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.B_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.B_StabLowGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Chapagite':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.C_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.C_StabLowGood98_1[i])])\n",
    "    if data.Vignette[i] == 'Drol':\n",
    "        if data.Group[i] == 'Prop_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Stab_No_Loss':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood70_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_1':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood85_1[i])])\n",
    "        if data.Group[i] == 'Prop_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.D_PropLowGood98_1[i])])\n",
    "        if data.Group[i] == 'Stab_Loss_2':\n",
    "            low_eval = np.append(low_eval,[int(data.D_StabLowGood98_1[i])])\n",
    "            \n",
    "\n",
    "\n",
    "comp_high_diff = comp_eval - high_eval\n",
    "comp_avg_diff = comp_eval - [.5*high_eval[i]+.5*low_eval[i] for i in range(0,len(data))]\n",
    "high_low_diff = high_eval - low_eval                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Compressed and the causal claim High (the variable V-A in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Comp_High_Diff   R-squared:                       0.085\n",
      "Model:                            OLS   Adj. R-squared:                  0.071\n",
      "Method:                 Least Squares   F-statistic:                     5.878\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           1.53e-06\n",
      "Time:                        16:57:01   Log-Likelihood:                -829.89\n",
      "No. Observations:                 450   AIC:                             1676.\n",
      "Df Residuals:                     442   BIC:                             1709.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.0867      0.189     -0.458      0.647      -0.458       0.285\n",
      "Vignette                   -0.3890      0.219     -1.779      0.076      -0.819       0.041\n",
      "Condition                  -0.2029      0.189     -1.073      0.284      -0.575       0.169\n",
      "Loss                       -2.6728      0.913     -2.929      0.004      -4.466      -0.879\n",
      "Vignette:Condition         -0.2878      0.219     -1.316      0.189      -0.718       0.142\n",
      "Vignette:Loss               0.3125      1.119      0.279      0.780      -1.887       2.512\n",
      "Condition:Loss              0.6233      0.913      0.683      0.495      -1.170       2.417\n",
      "Vignette:Condition:Loss     0.7568      1.119      0.676      0.499      -1.443       2.957\n",
      "==============================================================================\n",
      "Omnibus:                       51.903   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              309.514\n",
      "Skew:                          -0.223   Prob(JB):                     6.16e-68\n",
      "Kurtosis:                       7.038   Cond. No.                         25.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),comp_high_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Comp_High_Diff'])\n",
    "mod = smf.ols(formula='Comp_High_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claim Compressed and the average of their evaluations of causal claims High and Low (the variable V-B in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Comp_Avg_Diff   R-squared:                       0.045\n",
      "Model:                            OLS   Adj. R-squared:                  0.030\n",
      "Method:                 Least Squares   F-statistic:                     3.003\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):            0.00432\n",
      "Time:                        16:57:01   Log-Likelihood:                -818.60\n",
      "No. Observations:                 450   AIC:                             1653.\n",
      "Df Residuals:                     442   BIC:                             1686.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.0161      0.184      0.088      0.930      -0.346       0.379\n",
      "Vignette                   -0.4793      0.213     -2.247      0.025      -0.899      -0.060\n",
      "Condition                  -0.1626      0.184     -0.881      0.379      -0.525       0.200\n",
      "Loss                       -1.2266      0.890     -1.378      0.169      -2.976       0.522\n",
      "Vignette:Condition         -0.2463      0.213     -1.155      0.249      -0.666       0.173\n",
      "Vignette:Loss               0.5753      1.092      0.527      0.598      -1.570       2.721\n",
      "Condition:Loss              0.3126      0.890      0.351      0.726      -1.436       2.062\n",
      "Vignette:Condition:Loss     0.7876      1.092      0.722      0.471      -1.358       2.933\n",
      "==============================================================================\n",
      "Omnibus:                       66.255   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              380.539\n",
      "Skew:                          -0.451   Prob(JB):                     2.33e-83\n",
      "Kurtosis:                       7.414   Cond. No.                         25.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),comp_avg_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'Comp_Avg_Diff'])\n",
    "mod = smf.ols(formula='Comp_Avg_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block regresses the difference between the participant's evaluation of the causal claims High and Low (the variable V-C in the paper) against the Vignette, Loss, Condition, and all interactions between the three independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          High_Low_Diff   R-squared:                       0.110\n",
      "Model:                            OLS   Adj. R-squared:                  0.096\n",
      "Method:                 Least Squares   F-statistic:                     7.808\n",
      "Date:                Fri, 21 Jan 2022   Prob (F-statistic):           6.33e-09\n",
      "Time:                        16:57:01   Log-Likelihood:                -665.39\n",
      "No. Observations:                 450   AIC:                             1347.\n",
      "Df Residuals:                     442   BIC:                             1380.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.2057      0.131      1.567      0.118      -0.052       0.464\n",
      "Vignette                   -0.1806      0.152     -1.190      0.235      -0.479       0.118\n",
      "Condition                   0.0806      0.131      0.615      0.539      -0.177       0.339\n",
      "Loss                        2.8926      0.633      4.569      0.000       1.648       4.137\n",
      "Vignette:Condition          0.0829      0.152      0.546      0.585      -0.215       0.381\n",
      "Vignette:Loss               0.5255      0.777      0.677      0.499      -1.001       2.052\n",
      "Condition:Loss             -0.6214      0.633     -0.982      0.327      -1.866       0.623\n",
      "Vignette:Condition:Loss     0.0616      0.777      0.079      0.937      -1.465       1.588\n",
      "==============================================================================\n",
      "Omnibus:                      224.811   Durbin-Watson:                   1.953\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1938.752\n",
      "Skew:                           1.969   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.375   Cond. No.                         25.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "arr = np.hstack((vignette.reshape(-1,1),condition.reshape(-1,1),loss_vals.reshape(-1,1),high_low_diff.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Vignette', 'Condition', 'Loss', 'High_Low_Diff'])\n",
    "mod = smf.ols(formula='High_Low_Diff ~ Vignette + Condition + Loss + Vignette:Condition + Vignette:Loss + Condition:Loss + Vignette:Condition:Loss', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block generates Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(10,8)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.lineplot(x=loss_vals-.002, y=comp_eval, marker='o', err_style='bars',ci=95,label=\"Compressed\",linewidth=3)\n",
    "ax = sns.lineplot(x=loss_vals, y=high_eval, marker='o', err_style='bars',ci=95,linestyle='dashed',label=\"High\",linewidth=3)\n",
    "ax = sns.lineplot(x=loss_vals+.002, y=low_eval, marker='o', err_style='bars',ci=95,linestyle='dotted',label=\"Low\",linewidth=3)\n",
    "ax.set(ylim=(0,3))\n",
    "ax.set_ylabel('Mean Evaluation of Causal Claim',fontsize=30)\n",
    "ax.set_xlabel('Loss',fontsize=30)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('study1_barplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_High ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_High\n",
      "                        Effect     df  MSE      F   ges p.value\n",
      "1                     Vignette 1, 148 2.21   1.41  .006    .237\n",
      "2                    Condition 1, 148 2.21 3.68 +  .016    .057\n",
      "3           Vignette:Condition 1, 148 2.21   0.39  .002    .531\n",
      "4                    Diff_Type 1, 148 1.23 5.69 *  .014    .018\n",
      "5           Vignette:Diff_Type 1, 148 1.23   1.55  .004    .215\n",
      "6          Condition:Diff_Type 1, 148 1.23   0.01 <.001    .912\n",
      "7 Vignette:Condition:Diff_Type 1, 148 1.23   1.56  .004    .214\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_70=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        subject_70 = np.append(subject_70,[i,i])\n",
    "\n",
    "evals_high_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        evals_high_70 = np.append(evals_high_70,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "    \n",
    "vignette_for_anova_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        vignette_for_anova_70 = np.append(vignette_for_anova_70,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':                                                       \n",
    "        condition_for_anova_70 = np.append(condition_for_anova_70,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':                                                      \n",
    "        loss_vals_for_anova_70 = np.append(loss_vals_for_anova_70,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        diff_type_70 = np.append(diff_type_70,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_70.reshape(-1,1),vignette_for_anova_70.reshape(-1,1),condition_for_anova_70.reshape(-1,1),loss_vals_for_anova_70.reshape(-1,1),evals_high_70.reshape(-1,1),diff_type_70.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_High','Diff_Type'])\n",
    "\n",
    "\n",
    "packageNames = (\"afex\", \"emmeans\")\n",
    "utils = rpackages.importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "\n",
    "packnames_to_install = [x for x in packageNames if not rpackages.isinstalled(x)]\n",
    "\n",
    "if len(packnames_to_install) > 0:\n",
    "    utils.install_packages(StrVector(packnames_to_install))\n",
    "\n",
    "# convert pandas DF (\"tmp\") to R data.frame\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_High\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and Low when Loss=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE       F   ges p.value\n",
      "1                     Vignette 1, 148 2.37    2.30  .010    .132\n",
      "2                    Condition 1, 148 2.37  3.06 +  .013    .082\n",
      "3           Vignette:Condition 1, 148 2.37    0.28  .001    .599\n",
      "4                    Diff_Type 1, 148 1.31 9.27 **  .022    .003\n",
      "5           Vignette:Diff_Type 1, 148 1.31  2.89 +  .007    .091\n",
      "6          Condition:Diff_Type 1, 148 1.31    0.00 <.001    .974\n",
      "7 Vignette:Condition:Diff_Type 1, 148 1.31    1.72  .004    .192\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_70 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        evals_low_70 = np.append(evals_low_70,[comp_eval[i],low_eval[i]])\n",
    "        \n",
    "        \n",
    "arr = np.hstack((subject_70.reshape(-1,1),vignette_for_anova_70.reshape(-1,1),condition_for_anova_70.reshape(-1,1),loss_vals_for_anova_70.reshape(-1,1),evals_low_70.reshape(-1,1),diff_type_70.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "        \n",
    "# convert pandas DF (\"tmp\") to R data.frame\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval\n",
      "                        Effect     df  MSE      F   ges p.value\n",
      "1                     Vignette 1, 137 2.63   0.31  .002    .580\n",
      "2                    Condition 1, 137 2.63   0.42  .002    .518\n",
      "3           Vignette:Condition 1, 137 2.63   0.84  .004    .361\n",
      "4                    Diff_Type 1, 137 1.28 2.82 +  .007    .096\n",
      "5           Vignette:Diff_Type 1, 137 1.28   1.42  .003    .235\n",
      "6          Condition:Diff_Type 1, 137 1.28   0.45  .001    .503\n",
      "7 Vignette:Condition:Diff_Type 1, 137 1.28   0.10 <.001    .748\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_85=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        subject_85 = np.append(subject_85,[i,i])\n",
    "\n",
    "evals_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        evals_85 = np.append(evals_85,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "vignette_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        vignette_for_anova_85 = np.append(vignette_for_anova_85,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':                                                       \n",
    "        condition_for_anova_85 = np.append(condition_for_anova_85,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':                                                     \n",
    "        loss_vals_for_anova_85 = np.append(loss_vals_for_anova_85,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        diff_type_85 = np.append(diff_type_85,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_85.reshape(-1,1),vignette_for_anova_85.reshape(-1,1),condition_for_anova_85.reshape(-1,1),loss_vals_for_anova_85.reshape(-1,1),evals_85.reshape(-1,1),diff_type_85.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between High and Low when Loss=.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE         F   ges p.value\n",
      "1                     Vignette 1, 137 2.71      0.68  .004    .413\n",
      "2                    Condition 1, 137 2.71      0.21  .001    .648\n",
      "3           Vignette:Condition 1, 137 2.71      1.17  .007    .281\n",
      "4                    Diff_Type 1, 137 0.73 23.47 ***  .035   <.001\n",
      "5           Vignette:Diff_Type 1, 137 0.73      1.12  .002    .291\n",
      "6          Condition:Diff_Type 1, 137 0.73      0.29 <.001    .591\n",
      "7 Vignette:Condition:Diff_Type 1, 137 0.73      0.60 <.001    .442\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_85 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        evals_low_85 = np.append(evals_low_85,[high_eval[i],low_eval[i]])\n",
    "        \n",
    "arr = np.hstack((subject_85.reshape(-1,1),vignette_for_anova_85.reshape(-1,1),condition_for_anova_85.reshape(-1,1),loss_vals_for_anova_85.reshape(-1,1),evals_low_85.reshape(-1,1),diff_type_85.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between Compressed and High when Loss=.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval\n",
      "                        Effect     df  MSE         F   ges p.value\n",
      "1                     Vignette 1, 153 2.82      0.02 <.001    .883\n",
      "2                    Condition 1, 153 2.82    5.71 *  .027    .018\n",
      "3           Vignette:Condition 1, 153 2.82      0.48  .002    .491\n",
      "4                    Diff_Type 1, 153 1.03 39.19 ***  .064   <.001\n",
      "5           Vignette:Diff_Type 1, 153 1.03      1.72  .003    .191\n",
      "6          Condition:Diff_Type 1, 153 1.03      0.03 <.001    .856\n",
      "7 Vignette:Condition:Diff_Type 1, 153 1.03      0.10 <.001    .750\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_98=[]\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        subject_98 = np.append(subject_98,[i,i])\n",
    "\n",
    "evals_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        evals_98 = np.append(evals_98,[comp_eval[i],high_eval[i]])\n",
    "    \n",
    "vignette_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        vignette_for_anova_98 = np.append(vignette_for_anova_98,[vignette[i],vignette[i]])\n",
    "    \n",
    "condition_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':                                                       \n",
    "        condition_for_anova_98 = np.append(condition_for_anova_98,[condition[i],condition[i]])\n",
    "    \n",
    "loss_vals_for_anova_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':                                                     \n",
    "        loss_vals_for_anova_98 = np.append(loss_vals_for_anova_98,[loss_vals[i],loss_vals[i]])\n",
    "    \n",
    "diff_type_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        diff_type_98 = np.append(diff_type_98,[-1,1])\n",
    "\n",
    "arr = np.hstack((subject_98.reshape(-1,1),vignette_for_anova_98.reshape(-1,1),condition_for_anova_98.reshape(-1,1),loss_vals_for_anova_98.reshape(-1,1),evals_98.reshape(-1,1),diff_type_98.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs the ANOVA analysis for the difference in evaluation between High and Low when Loss=.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Formula send to aov_car: Eval_Low ~ Vignette * Condition + Error(Subject/(Diff_Type))\n",
      "\n",
      "R[write to console]: Converting to factor: Vignette, Condition\n",
      "\n",
      "R[write to console]: Contrasts set to contr.sum for the following variables: Vignette, Condition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type 3 tests)\n",
      "\n",
      "Response: Eval_Low\n",
      "                        Effect     df  MSE          F   ges p.value\n",
      "1                     Vignette 1, 153 2.75       0.45  .002    .504\n",
      "2                    Condition 1, 153 2.75     2.83 +  .015    .095\n",
      "3           Vignette:Condition 1, 153 2.75       0.58  .003    .448\n",
      "4                    Diff_Type 1, 153 0.64 138.31 ***  .145   <.001\n",
      "5           Vignette:Diff_Type 1, 153 0.64       0.00 <.001    .975\n",
      "6          Condition:Diff_Type 1, 153 0.64     3.10 +  .004    .080\n",
      "7 Vignette:Condition:Diff_Type 1, 153 0.64       0.29 <.001    .594\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_low_98 = []\n",
    "for i in range(0,len(data.Group)):\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        evals_low_98 = np.append(evals_low_98,[high_eval[i],low_eval[i]])\n",
    "        \n",
    "arr = np.hstack((subject_98.reshape(-1,1),vignette_for_anova_98.reshape(-1,1),condition_for_anova_98.reshape(-1,1),loss_vals_for_anova_98.reshape(-1,1),evals_low_98.reshape(-1,1),diff_type_98.reshape(-1,1)))\n",
    "df = pd.DataFrame(arr,columns=['Subject','Vignette', 'Condition', 'Loss', 'Eval_Low','Diff_Type'])\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_from_pd_df = ro.conversion.py2rpy(df)\n",
    "\n",
    "r_from_pd_df.head()\n",
    "\n",
    "afex = rpackages.importr(\"afex\")\n",
    "\n",
    "model = afex.aov_ez(\n",
    "    id=\"Subject\",\n",
    "    dv=\"Eval_Low\",\n",
    "    between=[\"Vignette\", \"Condition\"],\n",
    "    within=\"Diff_Type\",\n",
    "    data=r_from_pd_df,\n",
    "    check_contrasts=True,  # 3-way interaction is unaffected by this, \"True\" is recommended\n",
    "    type=3,  # using so-called type 3 sums of squares\n",
    "    print_formula=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the perecentage of participants who strictly preferred Compressed to High across all three loss levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35526315789473684, 0.2127659574468085, 0.10191082802547771]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_loss_compressed_preferrers=0\n",
    "no_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss') and comp_eval[i]>high_eval[i]:\n",
    "        no_loss_compressed_preferrers=no_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_No_Loss' or data.Group[i] == 'Stab_No_Loss':\n",
    "        no_loss=no_loss+1\n",
    "\n",
    "moderate_loss_compressed_preferrers=0\n",
    "moderate_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1') and comp_eval[i]>high_eval[i]:\n",
    "        moderate_loss_compressed_preferrers=moderate_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_Loss_1' or data.Group[i] == 'Stab_Loss_1':\n",
    "        moderate_loss=moderate_loss+1\n",
    "        \n",
    "significant_loss_compressed_preferrers=0\n",
    "significant_loss=0\n",
    "for i in range(0,len(data.Group)):\n",
    "    if (data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2') and comp_eval[i]>high_eval[i]:\n",
    "        significant_loss_compressed_preferrers=significant_loss_compressed_preferrers+1\n",
    "    if data.Group[i] == 'Prop_Loss_2' or data.Group[i] == 'Stab_Loss_2':\n",
    "        significant_loss=significant_loss+1\n",
    "        \n",
    "[no_loss_compressed_preferrers/no_loss,moderate_loss_compressed_preferrers/moderate_loss,significant_loss_compressed_preferrers/significant_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
